import pandas as pd
import numpy as np


class NaiveBayes(object):
    """
    定义一个类用于实现朴素贝叶斯分类器
    """
    def get_train_set(self):
        """
        获取数据，并将其分为训练集与测试集
        """
        data_set = pd.read_excel(io="D:\dataset\mat.xlsx")  # 读取数据
        data_set_np = np.array(data_set)  # 将数据由dataframe类型转换为数组类型
        train_data = data_set_np[:316, :data_set_np.shape[1] - 1]  # 获取训练集数据
        # print(train_data)
        train_labels = data_set_np[:316, data_set_np.shape[1] - 2]  # 获取训练集数据的输出值，方便后续分类操作
        # print(type(train_labels), train_labels)
        train_labels = list(train_labels)  # 将训练集数据的输出值转换为列表类型
        # print(type(train_labels), len(train_labels))
        # 将训练集数据的输出值0-20的分数分为2个类别
        for i in range(len(train_labels)):
            if train_labels[i] < 11:
                train_labels[i] = 1  # 0-10分记为类别1
            else:
                train_labels[i] = 0  # 11-20分记为类别0
        test_data = data_set_np[316:, :data_set_np.shape[1] - 1]  # 获取测试集数据
        test_labels = data_set_np[316:, data_set_np.shape[1] - 2]  # 获取测试集数据的输出值
        test_labels = list(test_labels)  # 同样将数据以列表形式存储
        # print(test_data, test_labels)
        # 将测试集数据的输出值0-20的分数分为2个类别
        for i in range(len(test_labels)):
            if test_labels[i] < 11:
                test_labels[i] = 1  # 0-10分记为类别1
            else:
                test_labels[i] = 0  # 11-20分记为类别0
        # print('===>', test_labels)
        return train_data, train_labels, test_data, test_labels  # 返回训练集数据及类别、测试集数据及类别

    def classify(self, train_data, train_labels, features):
        """
        假设属性之间相互独立，通过计算联合概率密度与先验概率密度获得类条件概率密度
        再由类条件概率与先验概率计算得到样本的后验概率
        """
        # 求train_labels中每个类别的先验概率
        p_y = {}  # 以字典的形式存储每个类别的先验概率
        for label in train_labels:
            p_y[label] = train_labels.count(label) / float(len(train_labels))
        # print(p_y)
        # 求联合概率即类别与特征同时发生的概率
        p_xy = {}  # 以字典的形式存储联合概率
        for y in p_y.keys():
            y_index = [i for i, label in enumerate(train_labels) if label == y]  # labels中出现y值的所有数值的下标索引
            for j in range(len(features)):  # features[0] 在train_data[:,0]中出现的所有下标索引
                x_index = [i for i, feature in enumerate(train_data[:, j]) if feature == features[j]]
                xy_count = len(set(x_index) & set(y_index))  # set(x_index)&set(y_index)列出两个表相同的元素
                p_key = str(features[j]) + '*' + str(y)
                p_xy[p_key] = xy_count / float(len(train_labels))
        # print(p_xy)
        # 求条件概率即在某类别条件下，某个特征出现的概率
        p = {}  # 类似的，将类条件概率存储在字典中
        for y in p_y.keys():
            for x in features:  # P[x|y] = P[xy]/P[y]
                p_key = str(x) + '|' + str(y)
                p[p_key] = p_xy[str(x) + '*' + str(y)] / float(p_y[y])
        # print(p)
        # 结合上述的先验概率与条件概率，计算样本的后验概率
        f = {}  # 计算每个样本的后验概率，即在当前属性组合下，结果归为某一类的概率
        for y in p_y:
            f[y] = p_y[y]
            for x in features:
                f[y] = f[y] * p[str(x) + '|' + str(y)]  # P[y|X] = P[X|y]*P[y]/P[X]，P[X]可以不计算
        # print(f)
        features_label = max(f, key=f.get)  # 最终分类结果取概率最大值所对应的类别
        return features_label

    def test(self, train_data, train_labels, test_data, test_labels):
        """
        遍历测试集所有数据，计算每个属性组合的所属类别，并与该样本的标签类别进行比较，得到准确率以及分类结果矩阵
        """
        correct = 0  # 初始化正确分类个数
        clsf_m = np.zeros((5, 5))  # 初始化分类结果矩阵
        # print(clsf_m)
        for i in range(len(test_data)):
            features = test_data[i]  # 遍历测试集所有样本
            result = nb.classify(train_data, train_labels, features)  # 计算当前属性组合所属类别
            print(features, '属于', result)
            clsf_m[result - 1, test_labels[i] - 1] = clsf_m[result - 1, test_labels[i] - 1] + 1  # 更新测试集分类结果矩阵
            if result == test_labels[i]:
                correct += 1
        print(correct / float(len(test_labels)))  # 计算分类准确率
        print(clsf_m)  # 显示混淆矩阵


if __name__ == '__main__':
    nb = NaiveBayes()  # 将类实例化为对象，进而调用类方法完成样本分类
    # 获取训练集数据及类别标签、测试集数据及类别标签
    train_data, train_labels, test_data, test_labels = nb.get_train_set()
    # 调用test函数计算分类结果
    nb.test(train_data, train_labels, test_data, test_labels)

